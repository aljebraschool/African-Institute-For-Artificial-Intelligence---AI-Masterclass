{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Interactive Exercise: Data Preprocessing\n",
        "This notebook contains interactive coding exercises on [topic] using:\n",
        "- Fill-in-the-blanks activities\n",
        "- Bite-sized challenges\n",
        "- Debugging exercises\n",
        "\n",
        "\n",
        "## How to use this notebook:\n",
        "1. Make a copy to your own Google Drive\n",
        "2. Fill in the blank sections marked with TODO comments\n",
        "3. Run each cell to test your solutions\n",
        "4. Complete the challenges at your own pace"
      ],
      "metadata": {
        "id": "hKKMFGgMufq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question : Hands-on Practice Structure for Data Preprocessing\n",
        "## Here's how we can approach this with interactive elements:\n",
        "## Fill-in-the-Blanks Version:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "obPt8Ig1qvSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the blanks to complete the model training and evaluation pipeline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets, _________, _________\n",
        "from sklearn._________ import train_test_split\n",
        "from sklearn.preprocessing import _________\n",
        "from sklearn.linear_model import _________\n",
        "from sklearn.metrics import accuracy_score, _________, _________"
      ],
      "metadata": {
        "id": "50hR1DcEdhHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAaJJJpomutd"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in the blanks to complete the model training and evaluation pipeline\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = _________(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = _________()\n",
        "X_train_scaled = scaler._________(X_train)\n",
        "X_test_scaled = scaler._________(X_test)\n",
        "\n",
        "# Create and train the model\n",
        "model = _________(max_iter=1000)\n",
        "model._________(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model._________(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = _________(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display detailed classification report\n",
        "report = _________(y_test, y_pred)\n",
        "print(report)\n",
        "\n",
        "# Calculate and display confusion matrix\n",
        "cm = _________(y_test, y_pred)\n",
        "print(f\"Confusion Matrix:\\n{cm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bite-Sized Challenge:"
      ],
      "metadata": {
        "id": "m5r8Cme1rSo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bite-Sized Challenge: Comparing Different Classifiers\n",
        "# TODO: Complete the code to compare different classifiers on the same dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# TODO: Create a dictionary of classifiers to compare\n",
        "# Include at least 3 different classifiers from sklearn\n",
        "classifiers = {\n",
        "    # 'classifier_name': ClassifierClass(),\n",
        "    # Add more classifiers...\n",
        "}\n",
        "\n",
        "# TODO: Train each classifier and store accuracy scores\n",
        "results = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    # Train the classifier\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    # Make predictions\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    # Calculate accuracy\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    # Store the result\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "# TODO: Create a bar chart comparing the accuracy of different classifiers\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Print which classifier performed best on this dataset\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "gcEDQgowrUdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging Exercise:"
      ],
      "metadata": {
        "id": "hdXTssA5rcTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugging Exercise: Cross-Validation and Hyperparameter Tuning\n",
        "# This code has several bugs. Fix them to properly implement cross-validation and hyperparameter tuning.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load dataset\n",
        "digits = datasets.load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# BUG 1: Preprocessing is applied incorrectly\n",
        "scaler = StandardScaler\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# BUG 2: Cross-validation implementation has issues\n",
        "cv_scores = cross_val_score(SVC, X_scaled, y, cv=5)\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean CV Score: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# BUG 3: Grid search implementation has issues\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVC, param_grid, cv=5)\n",
        "grid_search.fit(X_scaled, y)\n",
        "\n",
        "# BUG 4: Accessing best parameters has issues\n",
        "best_params = grid_search.best_param_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "print(f\"Best cross-validation score: {best_score:.2f}\")\n",
        "\n",
        "# BUG 5: Final model training with best parameters has issues\n",
        "best_model = SVC(best_params)\n",
        "best_model.fit(X_scaled, y)"
      ],
      "metadata": {
        "id": "N4NurYOwrdO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}