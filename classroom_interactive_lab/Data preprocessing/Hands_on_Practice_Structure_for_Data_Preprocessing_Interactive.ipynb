{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Interactive Exercise: Data Preprocessing\n",
        "This notebook contains interactive coding exercises on [topic] using:\n",
        "- Fill-in-the-blanks activities\n",
        "- Bite-sized challenges\n",
        "- Debugging exercises\n",
        "\n",
        "\n",
        "## How to use this notebook:\n",
        "1. Make a copy to your own Google Drive\n",
        "2. Fill in the blank sections marked with TODO comments\n",
        "3. Run each cell to test your solutions\n",
        "4. Complete the challenges at your own pace"
      ],
      "metadata": {
        "id": "hKKMFGgMufq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question : Hands-on Practice Structure for Data Preprocessing\n",
        "## Here's how we can approach this with interactive elements:\n",
        "## Fill-in-the-Blanks Version:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "obPt8Ig1qvSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RPApWYi306Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAaJJJpomutd"
      },
      "outputs": [],
      "source": [
        "# Example: Feature Scaling Fill-in-the-blanks Exercise\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import _________, _________\n",
        "\n",
        "# Create sample data\n",
        "data = {\n",
        "    'feature1': [100, 200, 300, 400, 500],\n",
        "    'feature2': [0.5, 0.1, 0.9, 0.3, 0.7],\n",
        "    'feature3': [10, 5, 15, 20, 25]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Standardize feature1\n",
        "scaler1 = _________()\n",
        "df['feature1_scaled'] = scaler1._________(df[['feature1']])\n",
        "\n",
        "# Apply min-max scaling to feature2\n",
        "scaler2 = _________()\n",
        "df['feature2_scaled'] = _________._________(df[['feature2']])\n",
        "\n",
        "# Apply robust scaling to feature3\n",
        "scaler3 = _________()\n",
        "df['feature3_scaled'] = _________._________(df[['feature3']])\n",
        "\n",
        "# Compare results\n",
        "print(\"Original vs Scaled features:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bite-Sized Challenge:"
      ],
      "metadata": {
        "id": "m5r8Cme1rSo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small dataset with missing values\n",
        "data = {\n",
        "    'age': [25, 30, np.nan, 45, 33, np.nan],\n",
        "    'income': [50000, np.nan, 65000, 70000, np.nan, 62000],\n",
        "    'education': ['Bachelors', 'Masters', np.nan, 'PhD', 'Bachelors', 'Masters'],\n",
        "    'employed': [1, 1, 0, 1, np.nan, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Tasks:\n",
        "# 1. Count missing values in each column\n",
        "# 2. Drop rows where 'age' is missing\n",
        "# 3. Impute missing values in 'income' with mean\n",
        "# 4. Impute missing values in 'education' with mode\n",
        "# 5. Impute missing values in 'employed' with 0"
      ],
      "metadata": {
        "id": "gcEDQgowrUdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging Exercise:"
      ],
      "metadata": {
        "id": "hdXTssA5rcTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Debugging Exercise - Categorical Encoding\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create sample data\n",
        "data = {\n",
        "    'color': ['red', 'blue', 'green', 'red', 'yellow'],\n",
        "    'size': ['S', 'M', 'L', 'XL', 'M'],\n",
        "    'price': [10.5, 15.0, 20.0, 25.5, 17.0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# This preprocessing pipeline has errors\n",
        "# BUG 1: Incorrect implementation of one-hot encoding\n",
        "encoder = OneHotEncoder()\n",
        "encoded = encoder.fit_transform(df[['color', 'size']])\n",
        "# The above will work but doesn't return a DataFrame with column names\n",
        "\n",
        "# BUG 2: Incorrect concatenation attempt\n",
        "df_encoded = pd.concat([df, encoded], axis=1)\n",
        "# This won't work because encoded is not a DataFrame\n",
        "\n",
        "# Students need to fix the bugs to properly encode the categorical features"
      ],
      "metadata": {
        "id": "N4NurYOwrdO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}