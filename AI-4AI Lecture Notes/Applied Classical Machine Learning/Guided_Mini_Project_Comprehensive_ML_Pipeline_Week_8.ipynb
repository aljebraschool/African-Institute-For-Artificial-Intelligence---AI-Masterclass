{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Applied Classical Machine Learning\n",
        "In this comprehensive mini-project, you'll build an end-to-end machine learning pipeline that integrates all concepts learned from weeks 1-7. You'll work with a real-world dataset to perform classification and regression tasks, applying advanced techniques including ensemble methods, regularization, and unsupervised learning.\n"
      ],
      "metadata": {
        "id": "ck1_HE6ofcSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Setup"
      ],
      "metadata": {
        "id": "t8gmsEopfq2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3RlhPq2fXIR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets, metrics, model_selection, preprocessing\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Data Loading and Initial Exploration (Week 1 Concepts)"
      ],
      "metadata": {
        "id": "fyd5EvobfzAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Wine dataset for classification and Boston Housing for regression\n",
        "from sklearn.datasets import load_wine, load_boston\n",
        "\n",
        "# Load datasets\n",
        "wine_data = load_wine()\n",
        "X_wine = wine_data.data\n",
        "y_wine = wine_data.target\n",
        "wine_features = wine_data.feature_names\n",
        "\n",
        "# For regression, we'll use California housing dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing_data = fetch_california_housing()\n",
        "X_housing = housing_data.data\n",
        "y_housing = housing_data.target\n",
        "housing_features = housing_data.feature_names\n",
        "\n",
        "# TODO: Create pandas DataFrames for both datasets\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Display basic information about both datasets (shape, data types, etc.)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Display statistical summary of the features for both datasets\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Check for missing values in both datasets\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Identify and understand the ML problem types (supervised vs unsupervised)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Perform proper train-test split for both datasets (80% train, 20% test)\n",
        "# Remember to use random_state for reproducibility\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "EwALeHeEfvmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Data Preprocessing and Feature Engineering"
      ],
      "metadata": {
        "id": "MJoK2lsQf6oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Scale the features using StandardScaler for both datasets\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Create polynomial features for the housing dataset (degree=2)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Visualize the distribution of target variables\n",
        "# Create histograms for both classification and regression targets\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Create correlation heatmaps for both datasets\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Handle any data quality issues (outliers, skewness)\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "E03mlX_xf3xQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Linear Models and Regularization (Weeks 2-3)"
      ],
      "metadata": {
        "id": "UhPtzIp0gAme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement Linear Regression on housing data\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Implement Ridge Regression with different alpha values\n",
        "# Test alpha values: [0.1, 1.0, 10.0, 100.0]\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Implement Lasso Regression with different alpha values\n",
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "# TODO: Compare all regression models using cross-validation\n",
        "# Use 5-fold cross-validation and report mean and std of scores\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Visualize learning curves for the best performing model\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ULBlwFJRf9dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Tasks"
      ],
      "metadata": {
        "id": "j06NgAGuY8bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement Logistic Regression on wine data\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Tune the threshold for precision-recall tradeoff\n",
        "# Create precision-recall curves\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Handle class imbalance if present\n",
        "# Check class distribution and apply appropriate techniques\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "wzCQGFEGZNqL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Advanced Classification Methods (Weeks 4-5)"
      ],
      "metadata": {
        "id": "HPIdcRvGgGzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement SVM with different kernels (linear, rbf, poly)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Tune SVM hyperparameters (C, gamma) using GridSearchCV\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Implement Decision Tree Classifier\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Visualize the decision tree (limit max_depth to 3 for visualization)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Calculate and interpret classification metrics\n",
        "# Include precision, recall, F1-score, and accuracy\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Create and interpret confusion matrices\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "dJ8bagwKgDa4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Ensemble Methods (Week 6)"
      ],
      "metadata": {
        "id": "DkwkJkHUgQup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement Random Forest for both classification and regression\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Analyze feature importance from Random Forest\n",
        "# Create visualizations showing top 10 most important features\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Implement Gradient Boosting (XGBoost if available, otherwise use sklearn's GradientBoosting)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Compare ensemble methods with single models\n",
        "# Create a comparison table of all model performances\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "g3xwVT1_gJtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Unsupervised Learning (Week 7)"
      ],
      "metadata": {
        "id": "SZ_FRxiTglAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Apply K-means clustering to the wine dataset\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Determine optimal number of clusters using elbow method\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Implement hierarchical clustering and create dendrogram\n",
        "# YOUR CODE HERE\n",
        "\n"
      ],
      "metadata": {
        "id": "FBq8uMFIgUKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Pipeline Creation and Deployment Preparation"
      ],
      "metadata": {
        "id": "iVJO8beTgrKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create a complete ML pipeline using sklearn Pipeline\n",
        "# Include preprocessing, feature selection, and model training\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Test your pipeline with sample data\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "WWQ2McmOgoqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Submission Instructions**\n",
        "\n",
        "1. Complete all the TODO sections in this notebook\n",
        "2. Run all cells to ensure everything works as expected\n",
        "3. Save your notebook with your name (e.g., \"firstname_lastname_diabetes_prediction.ipynb\")\n",
        "4. Submit the notebook file through the course portal (Github repository)"
      ],
      "metadata": {
        "id": "d_6YkgcXg1ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grading Criteria:**\n",
        "\n",
        "- Code functionality and correctness (40%)\n",
        "- Proper data exploration and visualization (20%)\n",
        "- Model selection and evaluation (20%)\n",
        "- Hyperparameter tuning (10%)\n",
        "- Code organization and documentation (10%)"
      ],
      "metadata": {
        "id": "BDbFRtf3hKr0"
      }
    }
  ]
}